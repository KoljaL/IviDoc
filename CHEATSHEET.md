# IviDoc - Schnellreferenz
# Generated by Copilot

## üöÄ Erste Installation

### Automatisch (empfohlen)
```bash
# Alles in einem
./quickstart.sh          # Mit AI
./setup.sh --ai          # Mit AI + Details
./setup.sh               # Ohne AI
```

**Was wird automatisch installiert:**
- Docker CLI (24.0.5)
- Docker Compose (2.24.1)
- Colima (0.6.14) - Docker VM f√ºr macOS
- Alle Container-Images

**Keine Homebrew, keine Docker Desktop n√∂tig!**

### Colima (Docker VM) verwalten
```bash
# Status
colima status

# Starten
colima start

# Stoppen (spart RAM)
colima stop

# Neustarten
colima restart

# L√∂schen & neu erstellen
colima delete
colima start --arch aarch64 --cpu 4 --memory 8
```

## üê≥ Docker-Befehle

### Starten/Stoppen
colima stop

# Neustarten
colima restart

# L√∂schen & neu erstellen
colima delete
colima start --arch aarch64 --cpu 4 --memory 8
```

### Starten/Stoppen
```bash
# Standard (ohne AI)
docker compose up -d
docker compose stop
docker compose restart

# Mit AI-Profil
docker compose --profile ai up -d
docker compose stop ollama paperless-ai  # Nur AI stoppen

# Status
docker compose ps
docker compose logs -f paperless
```

### Setup-Scripte
```bash
./quickstart.sh     # Schnellster Start mit AI
./setup.sh          # Standard ohne AI
./setup.sh --ai     # Mit AI
./ai-setup.sh       # AI nachtr√§glich aktivieren
./backup.sh         # Backup erstellen
```

## üì± Dokumente verarbeiten

### PDFs importieren
```bash
# Vom Downloads-Ordner
cp ~/Downloads/*.pdf ./consume/

# Von iCloud
cp ~/Library/Mobile\ Documents/com~apple~CloudDocs/Scans/*.pdf ./consume/

# Status pr√ºfen
docker compose logs -f paperless | grep Consumer
```

### Ordner-Sync (optional)
```bash
# Symlink zu iCloud erstellen
ln -s ~/Library/Mobile\ Documents/com~apple~CloudDocs/Scans ./consume/scans
```

## ü§ñ AI/LLM verwenden

### Modelle verwalten
```bash
# Installieren
docker compose exec ollama ollama pull llama3.2
docker compose exec ollama ollama pull mistral

# Auflisten
docker compose exec ollama ollama list

# L√∂schen
docker compose exec ollama ollama rm <model>

# Testen
docker compose exec ollama ollama run llama3.2 "Hallo!"
```

### API-Zugriff
```bash
# Einfache Anfrage
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt": "Fasse diesen Text zusammen: ...",
  "stream": false
}'

# Chat
curl http://localhost:11434/api/chat -d '{
  "model": "llama3.2",
  "messages": [{"role": "user", "content": "Hallo"}]
}'
```

## üíæ Backup & Wartung

### Backup erstellen
```bash
# Manuelles Backup
./backup.sh

# Extern: Festplatte anpassen in backup.sh
nano backup.sh  # /Volumes/ExterneFestplatte √§ndern
```

### Updates installieren
```bash
# Standard
docker compose pull
docker compose up -d

# Mit AI
docker compose --profile ai pull
docker compose --profile ai up -d
```

### Datenbank-Wartung
```bash
# Im Container
docker compose exec paperless python manage.py document_sanity_checker
docker compose exec paperless python manage.py document_index reindex
```

## üîç Troubleshooting

### Logs ansehen
```bash
# Alle Services
docker compose logs

# Spezifischer Service
docker compose logs -f paperless
docker compose logs -f tika
docker compose logs -f ollama

# Letzte 50 Zeilen
docker compose logs --tail=50 paperless
```

### Container neustarten
```bash
# Einzeln
docker compose restart paperless
docker compose restart ollama

# Alle
docker compose restart
```

### Kompletter Neustart
```bash
docker compose down
docker compose up -d
# oder mit AI:
docker compose --profile ai up -d
```

### Datenbank zur√ºcksetzen (VORSICHT!)
```bash
# Backup erstellen!
./backup.sh

# Alles l√∂schen
docker compose down -v

# Neu starten
./setup.sh
```

## üìä System-Info

### Ressourcen
```bash
# Container-Statistiken
docker stats

# Festplatten-Nutzung
du -sh data/ media/ export/

# Docker-Volumes
docker system df
```

### Performance
```bash
# Worker erh√∂hen (bei viel RAM)
# In docker-compose.yml:
PAPERLESS_TASK_WORKERS: 4
PAPERLESS_THREADS_PER_WORKER: 4

# Dann:
docker compose up -d
```

## üîê Sicherheit & Zugriff

### Passwort √§ndern
Web-UI: Settings ‚Üí Users ‚Üí admin ‚Üí Change Password

### API-Token erstellen
Web-UI: Settings ‚Üí API Tokens ‚Üí Create

### Remote-Zugriff (optional)
```bash
# Via SSH-Tunnel
ssh -L 8000:localhost:8000 user@macbook-ip

# Dann lokal: http://localhost:8000
```

## üéØ Workflow-Tipps

### Erste 100 Dokumente
1. Kategorien anlegen: Finanzen, Medizin, Versicherung, etc.
2. Tags definieren: Bank, Strom, Wasser, Arzt, etc.
3. Korrespondenten: Firmen/Personen
4. Dokumenttypen: Rechnung, Vertrag, Bescheid, etc.
5. Manuell taggen (ML lernt ab ~50 Dokumenten)

### Ab 100 Dokumenten
1. AI-Profil aktivieren: `./ai-setup.sh`
2. Automatische Vorschl√§ge nutzen
3. Nur noch korrigieren statt neu taggen
4. Regelm√§√üig Backup: `./backup.sh`

### Batch-Import
```bash
# 100 PDFs auf einmal
cp scan_batch_01/*.pdf ./consume/

# Status
watch -n 5 'docker compose logs --tail=10 paperless | grep Consumer'
```

## üìö N√ºtzliche Links

- Web-UI: http://localhost:8000
- Ollama API: http://localhost:11434
- Docs: https://docs.paperless-ngx.com/
- GitHub: https://github.com/paperless-ngx/paperless-ngx

## üÜò H√§ufige Probleme

**OCR erkennt nichts:**
- PDF-Qualit√§t pr√ºfen (min. 200 DPI)
- Sprache pr√ºfen: Settings ‚Üí OCR ‚Üí Languages
- Tika-Logs: `docker compose logs tika`

**System langsam:**
- Workers erh√∂hen (siehe Performance)
- AI-Profil deaktivieren: `docker compose stop ollama paperless-ai`
- Nur n√∂tige Container laufen lassen

**Zu viel Festplatte:**
- Alte Exports l√∂schen: `rm -rf export/backup-*`
- Docker aufr√§umen: `docker system prune -a`

**RAM voll:**
- AI-Profil stoppen
- Kleineres LLM-Modell nutzen (llama3.2:1b)
- Workers reduzieren
