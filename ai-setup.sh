#!/bin/bash
# =====================================
# IviDoc AI-Profil Setup
# Aktiviert Ollama LLM + Paperless-AI
# =====================================

set -e

echo "ü§ñ IviDoc AI-Profil Setup"
echo "=========================="
echo ""

# -------------------
# Check Docker
# -------------------
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker nicht gefunden!"
    echo "   Bitte erst: ./setup.sh --ai"
    exit 1
fi

if ! docker ps &> /dev/null; then
    echo "‚ùå Docker l√§uft nicht!"
    if command -v colima &> /dev/null; then
        echo "üöÄ Starte Colima..."
        colima start --arch aarch64 --cpu 4 --memory 8
    else
        echo "   Bitte Docker Desktop starten."
        exit 1
    fi
fi

echo "‚úÖ Docker l√§uft"
echo ""

# Pr√ºfen ob Basis-System l√§uft
if ! docker compose ps | grep -q "paperless.*running"; then
    echo "‚ùå Paperless l√§uft nicht!"
    echo "   Bitte erst Basis-System starten: docker compose up -d"
    exit 1
fi

echo "‚úì Basis-System l√§uft"
echo ""

# AI-Profil starten
echo "üöÄ Starte AI-Services (Ollama + Paperless-AI)..."
docker compose --profile ai up -d

echo ""
echo "‚è≥ Warte auf Ollama-Start (15 Sek)..."
sleep 15

# Modell-Empfehlungen
echo ""
echo "üìö LLM-Modell installieren:"
echo ""
echo "Empfohlene Modelle f√ºr M4 MacBook Air:"
echo ""
echo "1. LeoLM 13B (DEUTSCH) - Beste Wahl f√ºr deutsche Dokumente"
echo "   ./install-leolm.sh"
echo "   Gr√∂√üe: ~7.5 GB"
echo ""
echo "2. Llama 3.2 (3B) - Schnell, Deutsch OK"
echo "   docker compose exec ollama ollama pull llama3.2"
echo "   Gr√∂√üe: ~2.8 GB"
echo ""
echo "3. Qwen2.5 (14B) - Sehr gut f√ºr Dokumente"
echo "   docker compose exec ollama ollama pull qwen2.5:14b"
echo "   Gr√∂√üe: ~9 GB"
echo ""
read -p "M√∂chten Sie jetzt LeoLM 13B (Deutsch) installieren? (j/n) " -n 1 -r
echo ""

if [[ $REPLY =~ ^[Jj]$ ]]; then
    echo ""
    echo "üì• Starte LeoLM Installation..."
    cd "$(dirname "$0")"
    chmod +x install-leolm.sh
    ./install-leolm.sh
fi

echo ""
echo "================================================"
echo "‚úÖ AI-Profil ist aktiv!"
echo "================================================"
echo ""
echo "üåê Paperless-NGX: http://localhost:8000"
echo "ü§ñ Ollama API:    http://localhost:11434"
echo ""
echo "üìä Status pr√ºfen:"
echo "   docker compose ps"
echo ""
echo "üí° Modell wechseln:"
echo "   docker compose exec ollama ollama list"
echo "   docker compose exec ollama ollama pull <model>"
echo ""
echo "üõë AI-Services stoppen:"
echo "   docker compose stop ollama paperless-ai"
echo ""
echo "================================================"
